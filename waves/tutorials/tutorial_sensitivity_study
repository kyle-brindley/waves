#! /usr/bin/env python
"""Rectangle compression workflow

Requires the following ``SConscript(..., exports={})``

* ``env`` - The SCons construction environment with the following required keys

  * ``abaqus_source_abspath`` - String absolute path to the project's Abaqus journal files
  * ``python_source_abspath`` - String absolute path to the project's Python 3 files
  * ``datacheck_alias`` - String for the alias collecting the datacheck workflow targets
  * ``regression_alias`` - String for the alias collecting the regression test suite targets
  * ``archive_prefix`` - String prefix for archive target(s) containing identifying project and version information
  * ``project_configuration`` - String absolute path to the project SCons configuration file
  * ``unconditional_build`` - Boolean flag to force building of conditionally ignored targets
  * ``abaqus`` - String path for the Abaqus executable
"""

import pathlib

from waves.parameter_generators import SET_COORDINATE_KEY
from waves.parameter_generators import SALibSampler

from modsim_package.python.rectangle_compression_sensitivity_study import parameter_schema

# Inherit the parent construction environment
Import("env")

# Comment used in tutorial code snippets: marker-1

# Set project-wide paths with os-agnostic path separators
abaqus_source_abspath = env["abaqus_source_abspath"]
python_source_abspath = env["python_source_abspath"]

# Simulation variables
build_directory = pathlib.Path(Dir(".").abspath)
workflow_name = build_directory.name
workflow_configuration = [env["project_configuration"], workflow_name]
parameter_study_file = build_directory / "parameter_study.h5"
model = "rectangle"
simulation_constants = {
    "global_seed": 1,
    "displacement": -0.01,
}
kwargs = {
    "seed": 42,
    "calc_second_order": False,
}

# Collect the target nodes to build a concise alias for all targets
workflow = []
datacheck = []

# Comment used in tutorial code snippets: marker-2

# Parameter Study with SALib Sobol sequence sampler
parameter_generator = SALibSampler(
    "sobol",
    parameter_schema(),
    output_file=parameter_study_file,
    previous_parameter_study=parameter_study_file,
    **kwargs,
)
parameter_generator.write()

# Comment used in tutorial code snippets: marker-3

# Parameterized targets must live inside current simulation_variables for loop
for set_name, parameters in parameter_generator.parameter_study_to_dict().items():
    set_name = pathlib.Path(set_name)
    simulation_variables = {**parameters, **simulation_constants}

    # Comment used in tutorial code snippets: marker-4

    # Geometry
    journal_file = f"{model}_geometry"
    journal_options = "--width ${width} --height ${height}"
    workflow.extend(
        env.AbaqusJournal(
            target=[f"{set_name / journal_file}.cae", f"{set_name / journal_file}.jnl"],
            source=[f"{abaqus_source_abspath / journal_file}.py"],
            subcommand_options=journal_options,
            **simulation_variables,
        )
    )

    # Partition
    journal_file = f"{model}_partition"
    journal_options = "--width ${width} --height ${height}"
    workflow.extend(
        env.AbaqusJournal(
            target=[f"{set_name / journal_file}.cae", f"{set_name / journal_file}.jnl"],
            source=[f"{abaqus_source_abspath / journal_file}.py", f"{set_name / model}_geometry.cae"],
            subcommand_options=journal_options,
            **simulation_variables,
        )
    )

    # Mesh
    journal_file = f"{model}_mesh"
    journal_options = "--global-seed ${global_seed}"
    workflow.extend(
        env.AbaqusJournal(
            target=[
                f"{set_name / journal_file}.inp",
                f"{set_name / journal_file}.cae",
                f"{set_name / journal_file}.jnl",
            ],
            source=[f"{abaqus_source_abspath / journal_file}.py", f"{set_name / model}_partition.cae"],
            subcommand_options=journal_options,
            **simulation_variables,
        )
    )

    # SolverPrep
    abaqus_source_list = [
        abaqus_source_abspath / f"{model}_compression.inp.in",
        abaqus_source_abspath / "assembly.inp",
        abaqus_source_abspath / "boundary.inp",
        abaqus_source_abspath / "field_output.inp",
        abaqus_source_abspath / "materials.inp",
        abaqus_source_abspath / "parts.inp",
        abaqus_source_abspath / "history_output.inp",
    ]
    abaqus_source_list = [pathlib.Path(source_file) for source_file in abaqus_source_list]
    workflow.extend(
        env.CopySubstfile(
            abaqus_source_list,
            substitution_dictionary=env.SubstitutionSyntax(simulation_variables),
            build_subdirectory=set_name,
        )
    )

    # Comment used in tutorial code snippets: marker-5

    # Abaqus Solve
    solve_source_list = [f"{set_name / source_file.name.rstrip('.in')}" for source_file in abaqus_source_list]
    solve_source_list.append([f"{set_name / journal_file}.inp"])
    job_name = pathlib.Path(solve_source_list[0]).stem
    datacheck_name = f"{job_name}_DATACHECK"
    datacheck_suffixes = ("023", "mdl", "sim", "stt")
    abaqus_options = "-double both"
    datacheck.extend(
        env.AbaqusSolver(
            target=[f"{set_name / datacheck_name}.{suffix}" for suffix in datacheck_suffixes],
            source=solve_source_list,
            job_name=datacheck_name,
            abaqus_options=f"{abaqus_options} -datacheck",
        )
    )

    workflow.extend(
        env.AbaqusSolver(
            target=[f"{set_name / job_name}.sta"],
            source=solve_source_list,
            job_name=job_name,
            abaqus_options=abaqus_options,
        )
    )

    # Extract Abaqus
    extract_source_list = [f"{set_name / job_name}.odb"]
    workflow.extend(
        env.AbaqusExtract(
            target=[f"{set_name / job_name}.h5"],
            source=extract_source_list,
        )
    )

# Comment used in tutorial code snippets: marker-6

# Post-processing
script = python_source_abspath / "sensitivity_study.py"
post_processing_source = [
    f"{pathlib.Path(set_name) / job_name}_datasets.h5"
    for set_name in parameter_generator.parameter_study[SET_COORDINATE_KEY].values
]
script_options = "--input-file ${SOURCES[2:].abspath}"
script_options += " --output-file ${TARGET.file}"
script_options += " --parameter-study-file ${SOURCES[1].abspath}"
workflow.extend(
    env.PythonScript(
        target=["sensitivity_study.pdf", "sensitivity_study.csv", "sensitivity_study.yaml"],
        source=[script, parameter_study_file.name] + post_processing_source,
        subcommand_options=script_options,
    )
)

# Data archival
archive_name = f"{env['archive_prefix']}-{workflow_name}.tar.bz2"
archive_target = env.Tar(
    target=archive_name,
    source=workflow + workflow_configuration,
)

# Collector alias based on parent directory name
env.Alias(workflow_name, workflow)
env.Alias(f"{workflow_name}_datacheck", datacheck)
env.Alias(env["datacheck_alias"], datacheck)
env.Alias(env["regression_alias"], datacheck)
env.Alias(f"{workflow_name}_archive", archive_target)

if not env["unconditional_build"] and not env["ABAQUS_PROGRAM"]:
    print(f"Program 'abaqus' was not found in construction environment. Ignoring '{workflow_name}' target(s)")
    Ignore([".", workflow_name], workflow)
    Ignore([".", f"{workflow_name}_datacheck"], datacheck)
    Ignore([".", env["datacheck_alias"], env["regression_alias"]], datacheck)
