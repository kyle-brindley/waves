You should expect that the geometry and partition tasks do not need to re-execute because their output files still exist
and they are upstream of the mesh task. But the tasks after the mesh task did not re-execute, either. This should be
somewhat surprising. The simulation itself depends on the mesh file, so why didn't the workflow re-execute all tasks
from mesh to post-processing?

Many software build systems, such as `GNU Make`_ use file system modification time stamps to track DAG state
:cite:`gnu-make`. By default the `SCons`_ state machine uses file signatures built from md5 hashes to identify task
state. If the contents of the ``rectangle_mesh.inp`` file do not change, then the md5 signature on re-execution still
matches the build state for the rest of the downstream tasks, which do not need to rebuild.

This default behavior of `SCons`_ makes it desirable for computational science and engineering workflows where
downstream tasks may be computationally expensive. The added cost of computing md5 signatures during configuration is
valuable if it prevents re-execution of a computationally expensive simulation. In actual practice, production
engineering analysis workflows may include tasks and simulations with wall clock run times of hours to days. By
comparison, the cost of using md5 signatures instead of time stamps is often negligible.

Now run the mesh convergence study as below. `SCons`_ uses the ``--jobs`` option to control the number of threads used
in task execution and will run up to 4 tasks simultaneously.

.. code-block::

   $ scons mesh_convergence --jobs=4
   ...

The output is truncated, but should look very similar to the ``nominal`` output above, where the primary difference is
that each parameter set is nested one directory lower using the parameter set number.

.. code-block::

   $ ls build/mesh_convergence/
   parameter_set0/  parameter_set1/  parameter_set2/  parameter_set3/

These set names are managed by the |PROJECT| parameter study object, which is written to a separate build directory for
later re-execution. This parameter study file is used in the parameter study object construction to identify previously
created parameter sets on re-execution.

.. code-block::

   $ ls build/parameter_studies/
   mesh_convergence.h5
   $ waves print_study build/parameter_studies/mesh_convergence.h5
                                           set_hash  width  height  global_seed  displacement
   set_name
   parameter_set0  cf0934b22f43400165bd3d34aa61013f    1.0     1.0        1.000         -0.01
   parameter_set1  ee7d06f97e3dab5010007d57b2a4ee45    1.0     1.0        0.500         -0.01
   parameter_set2  93de452cc9564a549338e87ad98e5288    1.0     1.0        0.250         -0.01
   parameter_set3  49e34595c98442a228efd9e9765f61dd    1.0     1.0        0.125         -0.01

Try adding a new global mesh seed in the middle of the existing range. An example might look
like the following, where the seed ``0.4`` is added between ``0.5`` and ``0.25``.

.. code-block::
   :caption: SConstruct

   mesh_convergence_parameter_generator = waves.parameter_generators.CartesianProduct(
        {
           "width": [1.0],
           "height": [1.0],
           "global_seed": [1.0, 0.5, 0.4, 0.25, 0.125],
           "displacement": [-0.01],
       },
       output_file=mesh_convergence_parameter_study_file,
       previous_parameter_study=mesh_convergence_parameter_study_file
   )

Then re-run the parameter study. The new parameter set should build under the name ``parameter_set4`` and workflow
should build only ``parameter_set4`` tasks. The parameter study file should also be updated in the build directory.

.. code-block::

   $ scons mesh_convergence --jobs=4
   $ ls build/mesh_convergence/
   parameter_set0/  parameter_set1/  parameter_set2/  parameter_set3/ parameter_set4/
   $ waves print_study build/parameter_studies/mesh_convergence.h5
                                           set_hash  width  height  global_seed  displacement
   set_name
   parameter_set0  cf0934b22f43400165bd3d34aa61013f    1.0     1.0        1.000         -0.01
   parameter_set1  ee7d06f97e3dab5010007d57b2a4ee45    1.0     1.0        0.500         -0.01
   parameter_set2  93de452cc9564a549338e87ad98e5288    1.0     1.0        0.250         -0.01
   parameter_set3  49e34595c98442a228efd9e9765f61dd    1.0     1.0        0.125         -0.01
   parameter_set4  4a49100665de0220143675c0d6626c50    1.0     1.0        0.400         -0.01

If the parameter study naming convention were managed by hand it would likely be necessary to add the new seed to the
end of the parameter study to guarantee that the new set received a new set number. In practice, parameter studies are
often defined programmatically as a ``range()`` or vary more than one parameter, which makes it difficult to predict how
the set numbers may change. It would be tedious and error-prone to re-number the parameter sets such that the
input/output relationships are consistent. In the best case, mistakes in set re-numbering would result in unnecessary
re-execution of the previous parameter sets. In the worst case, mistakes could result in silent inconsistencies in
the input/output relationships and lead to errors in result interpretations.

|PROJECT| first looks for and opens the previous parameter study file saved in the build directory, reads the previous
set definitions if the file exists, and then merges the previous study definition with the current definition along the
unique set contents identifier coordinate. Under the hood, this unique identifier is an md5 hash of a string
representation of the set contents, which is robust between systems with identical machine precision. To avoid long,
unreadable hashes in build system paths, the unique md5 hashes are tied to the more human readable set numbers seen in
the mesh convergence build directory.
